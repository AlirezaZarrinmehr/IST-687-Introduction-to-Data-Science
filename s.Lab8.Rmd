---
output:
  pdf_document: default
  html_document: default
---

# Intro to Data Science - Lab 8
##### Copyright 2022, Jeffrey Stanton and Jeffrey Saltz   Please do not post online.

## Week 8 - Linear Models

```{r}
# Enter your name here: Alireza Zarrinmehr
```

### Please include nice comments. <br>
### Instructions: 
Run the necessary code on your own instance of R-Studio.

### Attribution statement: (choose only one and delete the rest)

```{r}
# 1. I did this lab assignment by myself, with help from the book and the professor.
```

**Linear	modeling**,	also	referred	to	as	**regression	analysis**	or	multiple regression **bold text**,	is	a	technique	for	fitting	a	line,	plane,	or	higher	order	linear	object	to	data.	<br><br>In	their	simplest	form,	linear	models	have	one	metric	**outcome	variable**	and	
one	or	more	**predictor	variables**	(any	combination	of	metric	values,	ordered	
scales	such	as	ratings,	or	dummy	codes).			<br><br>

Make	sure	to	library	the	**MASS**	and	**ggplot2** packages	before	running	the	following:	<br><br>


```
ggplot(data=Boston) + aes(x=rm, y=medv) + geom_point() +
 geom_smooth(method="lm", se=FALSE)
```



```{r}
library(ggplot2)
library(MASS)
ggplot(data=Boston) + aes(x=rm, y=medv) + geom_point() +
 geom_smooth(method="lm", se=FALSE)
```

1. Explore	this	dataset	descrption	by	typing	`?Boston` in a code cell.

```{r}
?Boston
```

2. The graphic you just created fits a best line to a cloud of points. Copy and
modify the code to produce a plot where ** crim ** is the x variable instead of ** rm**. 

```{r}
ggplot(data=Boston) + aes(x=crim, y=medv) + geom_point() +
 geom_smooth(method="lm", se=FALSE)
```

3. Produce a histogram and descriptive statistics for **Boston$crim**. Write a
comment describing any anomalies or oddities.

```{r}
summary(Boston)
hist(Boston$crim)
# data is right skewd 
```

4. Produce a linear model, using the **lm( )** function where **crim** predicts **medv**.<br><br>
Remember that in R s formula language, the **outcome variable** comes first and is
separated from the predictors by a **tilde**, like this: `medv ~ crim`<br><br>
Try to get in the habit of storing the output object that is produced by lm and
other analysis procedures. For example, I often use **lmOut <- lm( . . .)**

```{r}
lmOut <- lm(formula = medv~crim, data=Boston)
summary(lmOut)
```

5. Run a **multiple regression** where you use **rm**, **crim**, and **dis** (distance to Boston employment centers). You will use all three predictors in one model with this
formula:<br><br> `medv ~ crim + rm + dis` <br><br>Now run three separate models for each
independent variable separate.

```{r}
lmOutM <- lm(formula = medv ~ crim + rm + dis, data=Boston)
summary(lmOutM)
#For the multiple regression: 
  #we get the p-value: < 2.2e-16 and R-Squared of 0.53 that makes this the best model so far: Significant predictors are 
  #crim with a coefficient of -0.25405, rm with a coefficient of 8.34257
```

```{r}
lmOutR <- lm(formula = medv ~ rm, data=Boston)
summary(lmOutR)
#For the regression on rm: 
  #we get the p-value: < 2.2e-16 and R-Squared of 0.4825: Significant predictors are 
  #rm with a coefficient of 9.102
```

```{r}
lmOutD <- lm(formula = medv ~ dis, data=Boston)
summary(lmOutD)
#For the regression on dis: 
  #we get the p-value: 1.207e-08 and R-Squared of 0.0606: Significant predictors are 
  #dis with a coefficient of 1.0916
```

```{r}
lmOutC <- lm(formula = medv ~ crim, data=Boston)
summary(lmOutC)
#For the regression on crim: 
  #we get the p-value: < 2.2e-16 and R-Squared of 0.1491 : Significant predictors are 
  #crim with a coefficient of -0.41519
```

6. Interpret	the	results	of	your	analysis	in	a	comment.	Make	sure	to	mention	the	**p-value**,	the	**adjusted	R-squared**,	the	list	of **significant	predictors**	and	the	**coefficient** for	each	significant	predictor.

```{r}
#For the multiple regression: (This is the best model so far) 
  #we get the p-value: < 2.2e-16 and R-Squared of 0.53 that makes this the best model so far: Significant predictors are 
  #crim with a coefficient of -0.25405, rm with a coefficient of 8.34257
#For the regression on rm: 
  #we get the p-value: < 2.2e-16 and R-Squared of 0.4825: Significant predictors are 
  #rm with a coefficient of 9.102
#For the regression on dis: 
  #we get the p-value: 1.207e-08 and R-Squared of 0.0606: Significant predictors are 
  #dis with a coefficient of 1.0916
#For the regression on crim: 
  #we get the p-value: < 2.2e-16 and R-Squared of 0.1491 : Significant predictors are 
  #crim with a coefficient of -0.41519
```

7. Create	a	one-row	**data	frame**	that	contains	some	plausible	values	for	the predictors.	For	example,	this	data	frame	contains	the	median	values	for	each predictor:<br><br> `predDF <- data.frame(crim = 0.26, dis=3.2, rm=6.2)`<br><br>
The numbers used here were selected randomly by looking at min and max data
of the variables.

```{r}
predDF <- data.frame(crim = 0.26, dis=3.2, rm=6.2)
```

8. Use	the	**predict( )** command	to	predict	a	new	value	of	**medv** from	the	one-row	data	frame.	If	you	stored	the	output	of	your	lm	model	in **lmOut**,	the command	would	look	like	this:<br><br>	`predict(lmOut, predDF)`

```{r}
lmOutM <- lm(formula = medv ~ crim + rm + dis, data=Boston)
summary(lmOutM)
predict(lmOutM, predDF)
```

