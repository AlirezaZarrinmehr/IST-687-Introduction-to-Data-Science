---
output:
  pdf_document: default
  html_document: default
---

# Intro to Data Science - HW 7
##### Copyright 2022, Jeffrey Stanton, Jeffrey Saltz, and Jasmina Tacheva

```{r}
# Enter your name here: Alireza Zarrinmehr
```


### Attribution statement: (choose only one and delete the rest)

```{r}
# 1. I did this homework by myself, with help from the book and the professor.
```

In our last assignment, we explored **data visualization** in R using the **ggplot2** package. This homework continues to use ggplot, but this time, with maps.  In addition, we will merge datasets using the built-in **merge( )** function, which provides a similar capability to a **JOIN in SQL** (don't worry if you do not know SQL). Many analytical strategies require joining data from different sources based on a ** key **   a field that two datasets have in common. 

## Step 1: Load the food scarcity data

A. Limited access to supermarkets, supercenters, grocery stores, or other sources of healthy and affordable food may make it harder for some people to eat a healthy diet. There are many ways to measure food store access and many ways to define which areas are low access   neighborhoods that lack healthy food sources. In this homework assignment, we will focus on **accessibility to sources of healthy food, as measured by the distance to a store** in an area.

This dataset contains a variable, **LAPOP1_10**, which denotes the number of people living beyond 1 mile for urban areas or 10 miles for rural areas from a supermarket in all counties of the United States.

Read the data from the following URL: https://data-science-intro.s3.us-east-2.amazonaws.com/FoodInsecurity.csv

<br> Store it in a dataframe called **dfIns** and examine it, describing in a comment what you see.




```{r}
#Load the libraries
library(tidyverse)
library(ggplot2)
library(imputeTS)
library(RCurl)
library(jsonlite)
library(maps)
library(ggmap)
library(mapproj)
#Store the url
url <- "https://data-science-intro.s3.us-east-2.amazonaws.com/FoodInsecurity.csv"
#Read the csv from url and store it is dfIns database
dfIns <- read.csv(url)
#Explore the data base
head(dfIns)
#The database shows counties and their population. It also include the state, largest city, average family income, average poverty rate, and some redundant data.
```

B.	Calculate the **average** of **MedianFamilyIncome** in the dataframe. Why is using mean() directly not working? Find a way to correct the data type of this variable so you can calculate the average (and then calculate the average). If you still cannot get a value for the mean, you may need to take care of the missing values in this variable - the **imputeTS** package we have used before might help.

Hint: use **str(dfIns)** or **glimpse(dfIns)** to help understand the dataframe

```{r}
#Getting the type of MedianFamilyIncome 
typeof(dfIns$MedianFamilyIncome)
str(dfIns)
#mean(dfIns$MedianFamilyIncome) is not working because the data type is character
#Change the data tyoe of MedianFamilyIncome to numeric
dfIns$MedianFamilyIncome <- as.numeric(dfIns$MedianFamilyIncome)
#loading the library for interpolation of null values
# Interpolate thr null values in MedianFamilyIncome
dfIns$MedianFamilyIncome <- na_interpolation(dfIns$MedianFamilyIncome)
# Get the mean of MedianFamilyIncome
mean(dfIns$MedianFamilyIncome)
```

C.	What is the population of the smallest county in the dataframe? Which state is it in?

```{r}
# Get the population of the smallest county 
min(dfIns$Pop2010)
# Getting the state that has the county with the least population 
dfIns[which.min(dfIns$Pop2010),"State"]
```

D. It is hard to understand the significance of the values in **LAPOP1_10** (remember, this is the variable that shows the number of people living too far from a store and thus, considered at risk of food insecurity) without a reference point. Create a new column in **dfIns** called **insecurityRatio** which is the ratio of **LAPOP1_10** to **Pop2010** (the county's population) and describe in a comment what it means.

```{r}
# Adding a new variable to the data set that shows the insecurity ratio
dfIns$insecurityRatio <- dfIns$LAPOP1_10/dfIns$Pop2010
#Insecurity ratio is the percentage of people living beyond "1 mile for urban areas" or "10 miles for rural areas" from a supermarket in each county 
# Check the data set
head(dfIns)
```

E. Provide descriptive statistics for this new variable (e.g. min, max, mean, and standard deviation) and interpret them briefly. Then generate a histogram using ggplot, to confirm (or futher explore) those interpretations.

```{r}
#Getting the Min, 1st Qu, Median, Mean, 3rd Qu, and Max. 
summary(dfIns$insecurityRatio)
# Getting the standard deviation 
sd(dfIns$insecurityRatio)
# On average 24 percent of people are food insecure. 68 percent of the counties has the incsecurity ratio between 0.03 and 0.39

HistIR <- ggplot(dfIns, aes(x=insecurityRatio)) + 
  geom_histogram(color="black", fill="blue") + 
  # Add line for mean
  geom_vline(xintercept = mean(dfIns$insecurityRatio), col = "red", lwd = 3) +
  # Add text for mean
  annotate("text", x = .3, y = 300, label = "Mean",col = "red",size = 5) +
  # Add line for median
  geom_vline(xintercept = median(dfIns$insecurityRatio), col = "Purple", lwd = 3) +
  # Add text for median
  annotate("text", x = .1, y = 300, label = "Median",col = "Purple",size = 5) 

HistIR

#Histogram shows that the distribution iz not normal and most of the states have low food insecurity ratio

```

## Step 2: Merge the food insecurity data with the city data

A.	Read the following JSON file, https://intro-datascience.s3.us-east-2.amazonaws.com/cities.json and store it in a variable called **pop**.

Examine the resulting pop dataframe and add comments explaining what each column contains.

```{r}
#Store the url
urlcity <- "https://intro-datascience.s3.us-east-2.amazonaws.com/cities.json"
#Load the JSON data set
dfcity <- getURL(urlcity) 
#Convert the JSON format to a R workable file
pop <- jsonlite::fromJSON(dfcity) 
# Exploring pop
head(pop)
# Pop data set contains the cities and their populatin, the states that they are located in, their rank (in regard to population), the latitude and longitude. 
```

B.	To successfully merge the dataframe **dfIns** with the **pop** dataframe, we need to identify a **column they have in common** which will serve as the ** key ** to merge on. One column both dataframes have is the **city column** (in the case of **dfIns**, it's called **Largest_city**. However, the values in **city** may not necessarily be unique - there may be cities in different states that have the same name. It is far less likely to have two cities with identical names in the same state, however. Therefore, the **city_state** variable in **dfIns** looks like a good candidate to merge on. The only problem is that there is no such variable in the **pop** df per se. Let's go ahead and create it by concatenating the **city** and **state** columns in **pop**. The following code should work - explain in a comment what it does:  

```{r}
pop$city_state<-paste0(pop$city,", ",pop$state)
head(pop)
```

C.	Merge the two dataframes (using the **city_state column** from both dataframes), storing the resulting dataframe in **dfNew**.

```{r}
dfNew <- merge(pop, dfIns,by="city_state")
head(dfNew)
```

D.	Review the structure of **dfNew** and explain the columns (aka attributes) in that dataframe.

```{r}
str(dfNew)
 # city_state                city and the state the city is in
 # city                      name of the city
 # growth_from_2000_to_2013  growth of poulation from 2000 to 2013
 # latitude                  latitude of location
 # longitude                 longitude of location
 # population                population of the city
 # rank                      rank of the city in regard to its population
 # state                     the state each city is in
 # State                     redundant
 # County                    the county the city is in
 # Pop2010                   population of the county in 2012
 # LAPOP1_10                 the number of people living beyond 1 mile for urban areas or 10 miles for rural 
 #                              areas from a supermarket in all counties 
 # AveragePovertyRate        Average poverty rate in each county
 # MedianFamilyIncome        Median Family incon in each county
 # Largest_city              Largest city in each county
 # abbr                      abbreviation of the state name
 # insecurityRatio           the percentage of people living beyond "1 mile for urban areas" or "10 miles 
 #                              for ruralareas" from a supermarket in each county 
```

## Step 3: Visualize the data

E.	Plot points (on top of a map of the US) for **each city**. Have the **color** represent the **insecurityRatio**.

```{r}

pp <- c(left = min(dfNew$longitude),
bottom = min(dfNew$latitude),
right = max(dfNew$longitude),
top = max(dfNew$latitude))

mapCity <- get_stamenmap(bbox=pp,zoom=6)

ggmap(mapCity) + geom_point(data = dfNew,alpha=0.5,aes(x=longitude,y=latitude, color=dfNew$insecurityRatio))

```

F.	Add a block comment that critiques the resulting map. 

```{r}
#The insecurity ratio in cities on north, south-east, and south-west is pretty high.
```

## Step 4: Group by State

A.	Use **group_by()** and **summarise** to make a dataframe of state-by-state average **insecurityRatio**. Store the result in **dfSimple**.

```{r}
dfSimple <- dfNew%>%group_by(state)%>%summarise(mean(insecurityRatio))
dfSimple
```

B.	Name the most and least food-insecure states in **dfSimple** and show the code you used to determine them.

```{r}
# Changing the second column name to MIR
colnames(dfSimple)[2] <- "MIR"
dfSimple
# Getting the least food-insecure state
dfSimple[which.min(dfSimple$MIR),]
# Getting the most food-insecure state
dfSimple[which.max(dfSimple$MIR),]
```

## Step 5: Create a map of the U.S.,  with the color of the state representing insecurityRatio

A. Make sure to expand the limits correctly and that you have used **coord_map** appropriately. Comment on the resulting map - what insight can you get from it?

```{r}
library(maps)
library(mapproj)
library(tidyverse)
 
# get state data and arrests data
states <- map_data("state")
# Change the name of the region column to state
colnames(states)[5] <- "state"
# Make all the observation in state column lowercase
dfSimple$state <- tolower(dfSimple$state)
# Make all the observation in state column lowercase
states$state <- tolower(states$state)
# merge and sort (plots in order, sort ensures states filled in)
insecurityRatio.geo <- merge(states, dfSimple, sort = FALSE, by = "state")
insecurityRatio.geo <- insecurityRatio.geo[order(insecurityRatio.geo$order), ]
 
# plot 
ggplot(insecurityRatio.geo, aes(long, lat)) +
  geom_polygon(aes(group = group, fill = MIR)) +
  coord_map()

#We can see that California, North Carolina and vermont are the states that have the highest average food insecurity ratio. However, Wyoming has the lowest average food insecurity ratio.

```

